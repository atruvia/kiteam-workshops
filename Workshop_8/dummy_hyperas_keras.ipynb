{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    \n",
    "    from sklearn.datasets import fetch_california_housing\n",
    "    \n",
    "    dataset = fetch_california_housing()\n",
    "    \n",
    "    X_all = pd.DataFrame(dataset.data)\n",
    "    X_all.columns = dataset.feature_names\n",
    "    \n",
    "    y_all = pd.DataFrame(dataset.target)\n",
    "    y_all.columns = ['house value']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.15, random_state=42)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense({{choice([5,10])}}, input_dim=8, activation='relu', name='num_neurons'))  \n",
    "    \n",
    "    if {{choice(['one', 'two'])}} == 'two':\n",
    "        model.add(Dense(5, activation='relu', name='optional_dense'))\n",
    "    \n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
    "    \n",
    "    result = model.fit(X_train, y_train, \n",
    "                       batch_size={{choice([64, 128])}}, \n",
    "                       epochs=1, \n",
    "                       validation_split=0.15)\n",
    "\n",
    "    validation_mse = np.amin(result.history['val_mean_squared_error']) \n",
    "\n",
    "    print('Best validation mae of epoch:', validation_mse)\n",
    "    \n",
    "    return {'loss': validation_mse, 'status': STATUS_OK, 'model': model}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "from __future__ import print_function\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.core import Dense, Dropout, Activation\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.optimizers import RMSprop\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.datasets import mnist\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils import np_utils\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.datasets import fetch_california_housing\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'Dense': hp.choice('Dense', [5,10]),\n",
      "        'Dense_1': hp.choice('Dense_1', ['one', 'two']),\n",
      "        'batch_size': hp.choice('batch_size', [64, 128]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "  1: \n",
      "  2: \n",
      "  3: from sklearn.datasets import fetch_california_housing\n",
      "  4: \n",
      "  5: dataset = fetch_california_housing()\n",
      "  6: \n",
      "  7: X_all = pd.DataFrame(dataset.data)\n",
      "  8: X_all.columns = dataset.feature_names\n",
      "  9: \n",
      " 10: y_all = pd.DataFrame(dataset.target)\n",
      " 11: y_all.columns = ['house value']\n",
      " 12: \n",
      " 13: X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.15, random_state=42)\n",
      " 14: \n",
      " 15: \n",
      " 16: \n",
      " 17: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "  1: def keras_fmin_fnct(space):\n",
      "  2: \n",
      "  3: \n",
      "  4:     model = Sequential()\n",
      "  5:     model.add(Dense(space['Dense'], input_dim=8, activation='relu', name='num_neurons'))  \n",
      "  6:     \n",
      "  7:     if space['Dense_1'] == 'two':\n",
      "  8:         model.add(Dense(5, activation='relu', name='optional_dense'))\n",
      "  9:     \n",
      " 10:     model.add(Dense(1, activation='relu'))\n",
      " 11:     model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
      " 12:     \n",
      " 13:     result = model.fit(X_train, y_train, \n",
      " 14:                        batch_size=space['batch_size'], \n",
      " 15:                        epochs=1, \n",
      " 16:                        validation_split=0.15)\n",
      " 17: \n",
      " 18:     validation_mse = np.amin(result.history['val_mean_squared_error']) \n",
      " 19: \n",
      " 20:     print('Best validation mae of epoch:', validation_mse)\n",
      " 21:     \n",
      " 22:     return {'loss': validation_mse, 'status': STATUS_OK, 'model': model}\n",
      " 23: \n",
      "Train on 14912 samples, validate on 2632 samples\n",
      "Epoch 1/1\n",
      "14912/14912 [==============================] - 0s 25us/step - loss: 5.6050 - mean_squared_error: 5.6050 - val_loss: 5.6556 - val_mean_squared_error: 5.6556\n",
      "Best validation mae of epoch: 5.655623398290942\n",
      "Train on 14912 samples, validate on 2632 samples\n",
      "Epoch 1/1\n",
      "14912/14912 [==============================] - 0s 24us/step - loss: 11.2011 - mean_squared_error: 11.2011 - val_loss: 6.1473 - val_mean_squared_error: 6.1473\n",
      "Best validation mae of epoch: 6.147255645334539\n",
      "Train on 14912 samples, validate on 2632 samples\n",
      "Epoch 1/1\n",
      "14912/14912 [==============================] - 0s 17us/step - loss: 5.8010 - mean_squared_error: 5.8010 - val_loss: 5.6614 - val_mean_squared_error: 5.6614\n",
      "Best validation mae of epoch: 5.661351073476681\n",
      "Train on 14912 samples, validate on 2632 samples\n",
      "Epoch 1/1\n",
      "14912/14912 [==============================] - 0s 21us/step - loss: 5.6051 - mean_squared_error: 5.6051 - val_loss: 5.6620 - val_mean_squared_error: 5.6620\n",
      "Best validation mae of epoch: 5.6620003604599045\n",
      "Train on 14912 samples, validate on 2632 samples\n",
      "Epoch 1/1\n",
      "14912/14912 [==============================] - 0s 20us/step - loss: 6104.9763 - mean_squared_error: 6104.9763 - val_loss: 36.5849 - val_mean_squared_error: 36.5849\n",
      "Best validation mae of epoch: 36.58492698785382\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test = data()\n",
    "\n",
    "best_run, best_model = optim.minimize(model=model,\n",
    "                                      data=data,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=5,\n",
    "                                      trials=Trials(),\n",
    "                                      notebook_name='hyperas_sanity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best performing model chosen hyper-parameters:\n",
      "{'Dense': 0, 'Dense_1': 1, 'batch_size': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best performing model chosen hyper-parameters:\")\n",
    "print(best_run)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
